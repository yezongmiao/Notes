# 一. 网络模型描述
## 1.1 analysisTransformModel
和常规的方式一致,主编码器是由四个降采样的的5x5的卷积块构成，中间包含了3个GDN块，采用的通道数是3，192，192，192，192

## 1.2 synthesisTransformModel
也和常规的解码器网络一致，主要由四个上采样的块构成，nn.ConvTransposed2d 进行上采样，IGDN激活层进行激活。通道数是：192，192，192，192，3

## 1.3 Space2Depth和Depth2Space

这个就是一种采样分辨率和通道数量的相互转化， (w,h,c)<-->（w/2,h/2,4c）

## 1.4 h_analysisTransformModel

这里的的第一阶段的超先验模型经过了**一次**的降采样。

## 1.5 h_synthesisTransformModel

这里的的第一阶段的超先验模型经过了**一次**的上采样。

这里完成了主要的编解码器框架的搭建，接下来是细节上的处理问题

----

## 1.5 NeighborSample

不会对数据进行操作，就是提取每一次滑动窗口区域内的数值，如果一个kernel的size是3x3而且channels是128，则会提取3x3x128个数，感觉使用这种方式计算均值和方差会消耗很大的计算量。

## 1.6 GaussianModel

和之前论文中的一致，这里的设计可以通过广播机制进行自动调控为自适应的高斯模型或者是固定分布的高斯模型。

## 1.7 PredictionModel

这个网络接入在先验网络之后，在获取到均值和方差的信息之后，通过卷积核对均值信息再次进行一波卷积，使用fc再对其进行一波学习，得到均值，而方差处理的就比较潦草，直接exp之后进行输出。

## 1.8 BypassRound

四舍五入的量化情况，对于这种量化，其反向传播函数就是其本身。

## 1.9 SideInfoReconModel():

因为有两路的均值辅助信息接入，所以会设计几个上采样的层来保持接入的辅助信息的分辨率和main decoder的输出分辨率一致，最后通过几个卷积核进行卷积得到最终的输出结果Rec。

## 2.0 

