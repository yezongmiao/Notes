
# H265说明
- [H265说明](#h265说明)
  - [1.1 YUV格式情况](#11-yuv格式情况)
    - [1.1.1 YUV整体理解](#111-yuv整体理解)
    - [1.1.2 YUV采样格式](#112-yuv采样格式)
    - [1.1.3 YUV存储格式](#113-yuv存储格式)

## 1. 1 术语

GOP：图像组

IDR：特殊的I帧，避免了I后续的帧参考IDR帧以前的帧。

Slice: GOP的后续划分单位，每个GOP内部划分多个Slice，Slice独立编码。为了在数据丢失的情况下，进行重新同步。Slice不跨越帧进行编码，但是可以作为其他slice的参考。

CTU： Slice后续的划分情况，编码树单元。

CU：编码单元，有CTU根据RD决策划分得到的。

TU：变换单元。

PU：预测单元。

Tile: 与slice概念相似，但是有规则：一个Slice中的所有的CTU属于同一个Tile，或者一个Tile下的CTU属于同一个Slice。

SPS：将属于GOP层和Slice层共用的大部分语法元素游离出来组成序列参数集。包含了一个CVS（coded video sequence）中所有图像的公共参数。档次信息，分辨率开关标志。



## 1.2 YUV格式情况

### 1.2.1 YUV整体理解
[YUV_简书](https://www.jianshu.com/p/6a361e86ccd5)

yuv种类分为很多，可以理解是一个**二维的**，即空间间，和空间内，这样的表述，借鉴了h264中的帧间和帧内的思想。

**空间-内**：不同空间，即描述一个像素的bit数不同，比如yuv444，yuv422，yuv411，yuv420

**空间-间**：相同空间，即描述一个像素的bit数相同，但是存储方式不同，比如对于yuv420而言，又可细分为yuv420p，yuv420sp，nv21，nv12，yv12，yu12，I420

### 1.2.2 YUV采样格式

从空间的角度考虑YUV格式：

YUV 444  最完整的最理想的状态

      [ y u v ] [ y u v ] [ y u v ] [ y u v ]
      [ y u v ] [ y u v ] [ y u v ] [ y u v ]
      [ y u v ] [ y u v ] [ y u v ] [ y u v ]
      [ y u v ] [ y u v ] [ y u v ] [ y u v ]

YUV 422格式，在原来满的情况下，每行需要去掉两个u和两个v

      [ y u ] [ y v ] [ y u ] [ y v ]
      [ y v ] [ y u ] [ y v ] [ y u ]
      [ y u ] [ y v ] [ y u ] [ y v ]
      [ y v ] [ y u ] [ y v ] [ y u ]


YUV 411格式，原来yuv422的基础上，每行再去掉一个u和一个v

      [ y u ] [ y ] [ y v ] [ y ]
      [ y u ] [ y ] [ y v ] [ y ]
      [ y u ] [ y ] [ y v ] [ y ]
      [ y u ] [ y ] [ y v ] [ y ]

4. YUV 420格式，原来yuv422的基础上，拿掉两个v或者U，其实yuv420的取名方式不是很高明，**更确切的命名为yuv420yuv402**也就是第一行只有两个u，而第二行只有两个v

      [ y u ] [ y ] [ y u ] [ y ]
      [ y v ] [ y ] [ y v ] [ y ]
      [ y u ] [ y ] [ y u ] [ y ]

### 1.2.3 YUV存储格式

三种格式packet，planar，semi-plane

**packet**: 是打包格式，即存储yuv，然后再存储下一个yuv ..
**planar**是平面格式，即先存储y平面，再存储u平面，最后存储v平面(好像都是这种的)
**semi-planar**是两个平面，正常的planar是三个平面，即y平面，u平面，v平面，现在的semi-planar是两个平面，也就是说uv为同一个平面，即一个y平面，一个uv平面

探讨一下相同bit数的不同存储格式，主要讨论yuv422和yuv420：

1.  YUV422

yuyv（yuy2）

        [ y u ] [ y v ] [ y u ] [ y v ]
        [ y u ] [ y v ] [ y u ] [ y v ]
        [ y u ] [ y v ] [ y u ] [ y v ]
        [ y u ] [ y v ] [ y u ] [ y v ]

uyvy

        [ u y ] [ v y ] [ u y ] [ v y ]
        [ u y ] [ v y ] [ u y ] [ v y ]
        [ u y ] [ v y ] [ u y ] [ v y ]
        [ u y ] [ v y ] [ u y ] [ v y ]

yuv422p（yu16）

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ u u u u ]
        [ u u u u ]
        [ v v v v ]
        [ v v v v ]

（yv16）

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ v v v v ]
        [ v v v v ]
        [ u u u u ]
        [ u u u u ]

yuv422sp（nv16）

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ u v u v ]
        [ u v u v ]
        [ u v u v ]
        [ u v u v ]

2. yuv420

yuv420p（yu12 / I420）  **这个好像是最常用的格式，从YUV转RGB都是按照这个格式读取文件的流**

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ u u ]
        [ u u ]
        [ v v ]
        [ v v ]

或（yv12）

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ v v ]
        [ v v ]
        [ u u ]
        [ u u ]

yuv420sp（nv12）

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ u v u v ]
        [ u v u v ]

或（nv21）

        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ y y y y ]
        [ v u v u ]
        [ v u v u ]



## 2 整体框架介绍

![](https://img-blog.csdnimg.cn/d0381eedfa3c478ebd5a22af5cf756d1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-256yZ566r,size_20,color_FFFFFF,t_70,g_se,x_16)

整体框架图如上所示，包含了一下几个模块：

1. **帧内预测**：主要用于去除图像的空间相关性，根据编码后的重构快信息来预测当前像素块来去除空间冗余。
2. **帧间预测**：用于去除图像的时间相关性，帧间预测通过已编码的图像作为当前帧的参考图像。
3. **变换量化**：该模块通过对残差数据进行变换量化以去除频域相关性，对数据进行有损压缩。变换将图像从时域转化到频域，将能能量集中在低频区域。量化可以减少图像编码的动态范围。一般两个是独立的，但是这里两个过程是一起的，减少复杂度。
4. **去方块滤波**：基于块的视频编码中，形成的重构图像出现方块效应，采用去方块滤波可以达到削弱甚至消除块效应的目的，提高图像的质量。
5. **样点自适应补偿：**通过解析方块滤波后的像素的统计特性，为像素添加相对应的偏移量。一定程度上消除了振铃效应。
6. **熵编码：**将编码控制数据，量化变换系数，帧内预测数据，预计运动数据等等编码成二进制码流进行存储或者传输。

整体描述如下：

1. 需要明确，我们不直接编码图像/视频的像素值，因为很大的空域，时域冗余。
2. 使用帧内/帧间预测，通过各类的预测模式，得到图像的预测值，并且会把预测的模式编写进码流。
3. 对预测后的图像和原始的图像做差，得到残差图，残差图则是去除了很多空域、时域冗余之后的结果，也是我们要编码的木变。针对残差图，进行DCT系数变换，得到变换系数，进一步去除了冗余。
4. 在做完DCT变换之后，要对变换的系数进行熵编码，但是都是浮点型的不太好操作，所以要对这部分的系数进行量化，将浮点型量化成整形（也不一定，可以编码索引），随后对量化后的结果进行编码。
5. 使用熵编码对上述的量化系数进行编码，编码成码流之后，传输到解码器，对应的进行解码工作。在得到解码后的图像中，进行环路滤波。帧间编码方式会使用滤波后的图像进行预测，而帧内的不会，因为帧内的不参考其他的帧，而滤波工作只会在一帧编码结束后进行。

## 3 编码结构

### 3.1 概述

GOP：视频压缩时，分割成若干个图像组进行压缩，称之为:GOP(Group of pic)，一般有两种类型，开放和封闭式，封闭式的GOP以IDR图像开始，各个GOP之间独立编码，在开放的GOP中，第一个GOP以IDR开始编码，后续的GOP以non-IDR图像为编码结果，后面的GOP可以跨过non-IDR以第一个IDR为参考结果。

Slice:每个GOP内部划分为多个Slice，为了在数据丢失情况下进行重新同步。每个片由一个或多个片段（SliceSegment，SS）组成。

CTU:每个CTU包括一个亮度树形编码块(CodingTree BIock，CTB)和两个色差树形编码块。一个SS在编码时，先被分割为相同大小的CTU，每一个CTU按照四又树分割方式被划分为不同类型的
编码单元CU。

![image-20210916161035266](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210916161035266.png)

Tile单元和Slice单元的差别：

![image-20210916161944946](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210916161944946.png)

不要求水平和垂直边界均匀分布，可根据并行计算和差错控制的要求灵活掌握。通常情况下，每一个TiIe中包含的CTU数据是近似相等的。在编码时，图像中的所有TiIe按照扫描顺序进行处理，每个TiIe中的CTU也按照扫描顺序进行编码。一个TiIe包含的CTU个数和SIice中的CTU个数互不影响，图整幅图像被划分为9个TIIe，每个Tile都为矩形. 

Slice和Tile可以同时存在，但是必须满足以下的条件：

1. 一个Slice中的所有的CTU属于同一个Tile。
2. 一个Tile中的所有的CTU属于同一个Slice。

### 3.2 树形编码块

#### 3.2.1 CU块

在HEVC中，一副图像可以分为很多个不重叠的CTU块，在CTU块内部，采用四叉树的循环分层的结构， 下面是一个图像被分成若干个CTU块和划分为CU的示意图。

![image-20210917104635140](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917104635140.png)

一般CTU大小可以通过编码前利用cfg文件设置其大小，一般好像是64x64的寸尺，然后每个CTU在编码的时候会根据内容复杂度以及估计的RDO性能进行判决要不要进一步划分CU，CU的尺寸从 8x8到64x64不等，具体可以表达为：

![image-20210917105923461](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917105923461.png)

#### 3.2.2 预测单元

预测单元PU规定了编码单元的所有的预测模式，所有的和预测有关的东西，都是在预测单元部分**定义**的，但是实际操作并不是，比如根据预测的模式获取预测值的时候，是以TU为单位的。

一个2Nx2N的CU模式，帧内预测单元PU的可选模式只有2种，帧间预测有8种，具体如下：

![image-20210917110851013](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917110851013.png)

PU是在CU的基础上进行划分的，所以最小的PU块有4x4。在CU为8x8的时候应该不大可能出现类似于后面nRx2N的方式。具体会不会不太清楚额，感觉在编码中，最基本的单元应该是4x4的块，所以不太可能再吧4x4的块继续往下划分。

#### 3.2.3 变换单元

变换单元TU是独立完成变换和量化的基本单元，其尺寸也是灵魂变化的，可以支持的大小为4x4~32x32的编码变换，以TU级别进行变换和量化。在CU内部，允许TU跨越多个PU，以四叉树的结构进行划分。大块的TU模型可以更好地集中能量，而小块地TU能够保存更多地图像细节。这种灵活分割地结构，可以使得变换后地残差能量得到充分地压缩。

![image-20210917111904819](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917111904819.png)

## 4 预测编码

### 4.1 预测原理

根据某种模型或方法，对当前的样本值进行预测，并对样本真实值和预测值之间的差值进行编码。图像中相邻像素之间有较强的相关性，当前像素的灰度值与其相邻像素在很大概率上是接近的。因此，可以利用己编码的邻近像素预测当前像素值，并将真实值与预测值的差值进行编码，这样可以大大提高视频信号的压缩效率。

![image-20210917113238246](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917113238246.png)

所以实际上，为了能够编码残差，预测期在编码端和解码端都会进行配置。以保证 编码端的预测值和解码端的预测值是一致的。

在视频编码中，预测主要分为两种：

1. 帧内预测，利用当前图像内已经解码的像素生成预测值
2. 帧间预测，利用当前图像之前已编码图像的重建像素生成预测值。

### 4.2 帧内预测

利用视频空间域的相关性，使用当前当前图像已编码的像素预测像素，达到去除视频空域冗余的目的。将预测残差作为后续编码模块的输入，进行下一步的编码处理。设置当前的像素值$ f(x,y)$ , $(x,y)$为其左边，其由已经编码的重建值 :


$$
\tilde{f}(x,y)=\sum(a_{(k,l)}\tilde{f}(k,l))
$$

$a_{(k,l)}$ 为二维的预测系数，$k$, $l$ 是参考像素的左边位置，当前像素的真实值和预测值的残差$e(x,y)$如下：
$$
e(x,y)=f(x,y)-\tilde{f}(x,y)
$$
这部分的残差值也就是我们要编码的数值，帧内预测技术是消除视频空间冗余地主要技术之一

其中$a_{k,l}$代表着不同地预测系数，这部分的预测系数由预测模式决定.HEVC中规定了若干种预测模式，每种模式都对应一种纹理方向(DC模式除外)，当前块的预测像素由其预测方向上相邻快的边界重建像素生成，该方法使得编码器能够根据内容，自适应地选择预测模式。

为了选择最优地模式，HEVC设定了RDO准则进行选择：
$$
J=D+\lambda \cdot R
$$
$D$表示某个模式下的失真情况，$R$表示该模式下的码率损失（变换系数，模式信息，宏块划分信息），选择率失真代价最小的模式就是最好的。$\lambda$是拉格朗日因子，由某种方式确定。需要说明，最优的模式并不一定是残差最小的模式，而是最终代价最小的模式。

在H.264中一共规定了3种大小的亮度帧内预测块：4x4, 8x8, 16x16，4x4和8x8包含了9种的预测模式，4x4,16x16包含了4种预测模式, 亮度方面总共17种预测模式，简单介绍以下几种：

![image-20210917143958926](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917143958926.png)

1. 垂直模式，块内的所有的像素点都是由上面块的像素产生：

![image-20210917144123964](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917144123964.png)

2. 水平模式，和垂直模式差不多，但是方向是水平方向：

![image-20210917144530204](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917144530204.png)

3. DC模式，当前快预测像素都为其所有参考像素的平均值：

![image-20210917144608837](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917144608837.png)

4. Plane模式，当前块像素计算如下：

![image-20210917144641398](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917144641398.png)

![image-20210917144649754](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917144649754.png)

还有4x4模式种的9种预测模式与8x8中的9种预测模式，不例举。

#### 4.2.1帧内预测模式

HEVC亮度分量帧内模式预测支持5种寸尺大小的PU：4x4,8x8,16x16,64x64，其中每一种大小的PU都对应35种的预测模式，包括Planar模式，DC模式和33种角度模式。

![image-20210917160637422](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917160637422.png)

白色是被预测的块，灰色是参考块。相比于H264，增加了左下方块的边界像素作为当前块的编码参考。

其中35种模式的编号为：

![image-20210917160845557](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917160845557.png)

1. Planar模式：由H264种的Plane发展而来，主要用于预测像素的**平缓变化**。
2. DC模式：用于大面积平坦区域，由左侧和上方的参考像素平均值得到。
3. 角度模式：使用了33种角度预测，预测方向可以视为在水平或者垂直方向做一个偏移。![image-20210917161059378](C:\Users\11512\AppData\Roaming\Typora\typora-user-images\image-20210917161059378.png)

当前块的预测需要同时用到上方以及左侧的参考像素，为了能够使用同意的形式来计算预测像素值，采用了投影像素的方法，垂直类模式将左侧参考像素按照给定方向投影到上方参考像素的左侧。同理水平投影到上方参考像素的左侧。水平模式则将上方参考像素按照给定方向投影到左侧参考像素的上方。

#### 4.2.2 亮度模式的编码

模式信息是需要编码到码流中去的，但是对所有的模型信息独立编码会带来不必要的冗余，会利用相邻的PU的情况对该PU块的模型选择进行判决，实现创建一个候选列表CL[]：假设A的模式是ModeA，B的模式是ModeB，分以下情况：

（1）ModeA=ModeB：

1. 是Planar或者DC的情况，则CL[0]是Planar，CL[1]是DC, CL[2]是26--垂直模式。
2. 如果ModeA和B是角度模式：CL[0]是ModeA， CL[1]  和 CL[2]是与ModeA相邻的两个模式，注意，2 3 33相邻，33 34 3相邻。

（2）ModeA！=ModeB

1. CL[0]=ModeA， CL[1]=ModeB，CL[2]看情况而定，以下描述有优先级的：
2. 如果都不是Planar，则是Planar，如果都不是DC则是DC，如果都不满足，则是26（垂直模式）。

建立完CL之后，如果当前的最优模式是C，则如果出现在CL中，那么只要编码CL中的索引就好了，如果不在CL中出现，那么 1. 将CL中的候选模式从小到大重新排序。2. 遍历候选模式，分别于ModeC比较，如果$ModeC>=CL[I]$,则让ModeC--，遍历结束后对ModeC最终的数值编码。

色度的编码情况跳过。



## 5 环路滤波

### 去块滤波器

[CSDN-去方块滤波](https://blog.csdn.net/Dillon2015/article/details/104385174?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.control)

去块滤波器模块需要针对所有的PU,和TU边界中的8x8的块边界进行处理，包括两个环节：滤波决策和滤波操作。

1. 滤波决策，得到滤波强度（不滤波，弱滤波，强滤波）和滤波参数
2. 然后根据滤波强度决策滤波开关，选择对应的滤波参数对像素进行相应的修正。

![](https://img-blog.csdnimg.cn/20200218233811320.png)

对不同的视频内容以及不同的编码参数具有自适应的功能，对平滑处的不连续边界做强滤波处理，而对纹理较为丰富的区域弱滤波或者不滤波处理。此处有一个由量化决定的滤波阈值，当纹理复杂程度超过阈值的时候，则不用滤波，否则关闭。后续在再根据纹理，进行滤波强度的选择。![](https://img-blog.csdnimg.cn/32a7512ee6554db0a2ed0c6a5ba5962b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-256yZ566r,size_20,color_FFFFFF,t_70,g_se,x_16)

（a）图由于边界两侧平缓，就会有很明显 的边界，而（b）处的纹理比较多，所以可能使用弱的滤波，（c）的话，由于边界两边差别过于大，这部分的差别超过了滤波可能导致的差别，所以这可能是图像的内容导致的。



